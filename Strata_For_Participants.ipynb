{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: basic operations in Jupyter notebook, types of cells, executing cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data in a data frame using pandas, take a look at them, check the size of the data set, rename columns to something easier to type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5436, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_table('LAE_OII_Strata.txt')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'wavelength of EL (angstroms)', 'EL flux (erg/cm^2/s)',\n",
       "       'continuum flux density', 'EW observed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'wl', 'el', 'cont_flux', 'ew'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.rename(columns={'wavelength of EL (angstroms)': 'wl', 'EW observed': 'ew',\n",
    "                        'EL flux (erg/cm^2/s)': 'el', 'continuum flux density': 'cont_flux'},\n",
    "                inplace=True)\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at data properties divided by type to figure out some differences between LAEs and OIIs. Change settings to visualize all the columns in a data frame. Eliminate outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>wl</th>\n",
       "      <th>el</th>\n",
       "      <th>cont_flux</th>\n",
       "      <th>ew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4114.6</td>\n",
       "      <td>1.787900e-16</td>\n",
       "      <td>1.0146</td>\n",
       "      <td>99.5160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3869.9</td>\n",
       "      <td>6.304500e-17</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>146.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3962.6</td>\n",
       "      <td>6.446300e-17</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>113.1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3901.7</td>\n",
       "      <td>1.007500e-16</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>2424.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3954.3</td>\n",
       "      <td>7.311100e-17</td>\n",
       "      <td>1.0416</td>\n",
       "      <td>36.6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>1.019300e-16</td>\n",
       "      <td>1.7645</td>\n",
       "      <td>32.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3900.4</td>\n",
       "      <td>8.694700e-17</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>34.3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4078.7</td>\n",
       "      <td>5.521000e-17</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>110.9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4189.0</td>\n",
       "      <td>4.772500e-17</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>117.5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4043.9</td>\n",
       "      <td>7.296100e-17</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>164.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3946.8</td>\n",
       "      <td>6.707400e-17</td>\n",
       "      <td>0.5384</td>\n",
       "      <td>64.7330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4018.8</td>\n",
       "      <td>5.061900e-17</td>\n",
       "      <td>2.1919</td>\n",
       "      <td>12.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4032.3</td>\n",
       "      <td>4.901900e-17</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>336.5200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3972.3</td>\n",
       "      <td>6.318700e-17</td>\n",
       "      <td>1.7831</td>\n",
       "      <td>18.6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4084.2</td>\n",
       "      <td>1.029600e-16</td>\n",
       "      <td>1.1588</td>\n",
       "      <td>49.4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3823.4</td>\n",
       "      <td>6.891900e-17</td>\n",
       "      <td>0.5728</td>\n",
       "      <td>58.6690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4136.1</td>\n",
       "      <td>4.605600e-17</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>237.6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4034.5</td>\n",
       "      <td>3.186800e-16</td>\n",
       "      <td>2.1743</td>\n",
       "      <td>79.5790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>6.708100e-17</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>56.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4189.2</td>\n",
       "      <td>4.874700e-17</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>315.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3981.2</td>\n",
       "      <td>5.121300e-17</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>106.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4022.6</td>\n",
       "      <td>5.112800e-17</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>56.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4094.5</td>\n",
       "      <td>6.253300e-17</td>\n",
       "      <td>0.1557</td>\n",
       "      <td>224.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4175.0</td>\n",
       "      <td>5.547700e-17</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>162.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4103.0</td>\n",
       "      <td>4.736300e-17</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>196.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4136.1</td>\n",
       "      <td>6.081100e-17</td>\n",
       "      <td>0.4253</td>\n",
       "      <td>81.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3931.7</td>\n",
       "      <td>5.176400e-17</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>51.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4093.7</td>\n",
       "      <td>1.156200e-16</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>182.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4116.6</td>\n",
       "      <td>4.453100e-17</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>26.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4198.0</td>\n",
       "      <td>4.673800e-17</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>325.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4070.3</td>\n",
       "      <td>1.396600e-16</td>\n",
       "      <td>24.5670</td>\n",
       "      <td>3.1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4065.1</td>\n",
       "      <td>6.215900e-17</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>55.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3900.6</td>\n",
       "      <td>7.877400e-17</td>\n",
       "      <td>1.8786</td>\n",
       "      <td>21.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4124.9</td>\n",
       "      <td>6.791500e-17</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>97.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4105.0</td>\n",
       "      <td>4.936500e-17</td>\n",
       "      <td>0.3407</td>\n",
       "      <td>81.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3896.7</td>\n",
       "      <td>7.009800e-17</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>71.0520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3843.5</td>\n",
       "      <td>1.373600e-16</td>\n",
       "      <td>0.3806</td>\n",
       "      <td>177.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3887.2</td>\n",
       "      <td>5.153400e-17</td>\n",
       "      <td>1.6826</td>\n",
       "      <td>15.4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3967.3</td>\n",
       "      <td>5.680200e-17</td>\n",
       "      <td>11.1750</td>\n",
       "      <td>2.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4018.4</td>\n",
       "      <td>5.415700e-17</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>35.3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4146.8</td>\n",
       "      <td>4.966200e-17</td>\n",
       "      <td>0.5211</td>\n",
       "      <td>54.6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4187.9</td>\n",
       "      <td>9.293900e-17</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>232.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4146.9</td>\n",
       "      <td>1.470100e-16</td>\n",
       "      <td>1.4795</td>\n",
       "      <td>56.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4015.7</td>\n",
       "      <td>6.017200e-17</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>243.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4107.2</td>\n",
       "      <td>4.684900e-17</td>\n",
       "      <td>4.3242</td>\n",
       "      <td>6.0964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3878.2</td>\n",
       "      <td>5.799600e-17</td>\n",
       "      <td>0.2097</td>\n",
       "      <td>138.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3869.7</td>\n",
       "      <td>6.951100e-17</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>51.9930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3858.3</td>\n",
       "      <td>6.826700e-17</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>64.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3857.1</td>\n",
       "      <td>1.154500e-16</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>245.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4110.7</td>\n",
       "      <td>6.597700e-17</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>84.5350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4053.9</td>\n",
       "      <td>5.354400e-17</td>\n",
       "      <td>2.1974</td>\n",
       "      <td>13.3580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4066.4</td>\n",
       "      <td>9.140900e-17</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>353.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4173.2</td>\n",
       "      <td>7.573800e-17</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>292.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3912.9</td>\n",
       "      <td>1.425700e-16</td>\n",
       "      <td>0.3022</td>\n",
       "      <td>240.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4076.2</td>\n",
       "      <td>9.316900e-17</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>347.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4084.3</td>\n",
       "      <td>1.491600e-16</td>\n",
       "      <td>1.7091</td>\n",
       "      <td>48.5620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3996.2</td>\n",
       "      <td>2.032800e-16</td>\n",
       "      <td>0.4872</td>\n",
       "      <td>222.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3852.6</td>\n",
       "      <td>1.113900e-16</td>\n",
       "      <td>0.7407</td>\n",
       "      <td>74.4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>LAE</td>\n",
       "      <td>3841.8</td>\n",
       "      <td>1.190700e-16</td>\n",
       "      <td>1.7287</td>\n",
       "      <td>33.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>LAE</td>\n",
       "      <td>4081.4</td>\n",
       "      <td>7.338600e-17</td>\n",
       "      <td>1.1131</td>\n",
       "      <td>36.6330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4415 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type      wl            el  cont_flux         ew\n",
       "0     LAE  4114.6  1.787900e-16     1.0146    99.5160\n",
       "1     LAE  3869.9  6.304500e-17     0.2145   146.8200\n",
       "2     LAE  3962.6  6.446300e-17     0.2983   113.1900\n",
       "3     LAE  3901.7  1.007500e-16     0.0211  2424.6000\n",
       "4     LAE  3954.3  7.311100e-17     1.0416    36.6110\n",
       "8     LAE  4079.0  1.019300e-16     1.7645    32.0610\n",
       "9     LAE  3900.4  8.694700e-17     1.2852    34.3300\n",
       "11    LAE  4078.7  5.521000e-17     0.2762   110.9200\n",
       "12    LAE  4189.0  4.772500e-17     0.2376   117.5700\n",
       "13    LAE  4043.9  7.296100e-17     0.2425   164.1200\n",
       "14    LAE  3946.8  6.707400e-17     0.5384    64.7330\n",
       "15    LAE  4018.8  5.061900e-17     2.1919    12.4410\n",
       "16    LAE  4032.3  4.901900e-17     0.0790   336.5200\n",
       "17    LAE  3972.3  6.318700e-17     1.7831    18.6520\n",
       "18    LAE  4084.2  1.029600e-16     1.1588    49.4380\n",
       "19    LAE  3823.4  6.891900e-17     0.5728    58.6690\n",
       "20    LAE  4136.1  4.605600e-17     0.1106   237.6300\n",
       "21    LAE  4034.5  3.186800e-16     2.1743    79.5790\n",
       "22    LAE  4170.0  6.708100e-17     0.6858    56.7340\n",
       "23    LAE  4189.2  4.874700e-17     0.0904   315.6600\n",
       "24    LAE  3981.2  5.121300e-17     0.2539   106.6400\n",
       "25    LAE  4022.6  5.112800e-17     0.4867    56.7000\n",
       "26    LAE  4094.5  6.253300e-17     0.1557   224.6000\n",
       "27    LAE  4175.0  5.547700e-17     0.1981   162.8300\n",
       "28    LAE  4103.0  4.736300e-17     0.1351   196.8600\n",
       "29    LAE  4136.1  6.081100e-17     0.4253    81.5920\n",
       "30    LAE  3931.7  5.176400e-17     0.5206    51.2690\n",
       "31    LAE  4093.7  1.156200e-16     0.3546   182.2700\n",
       "32    LAE  4116.6  4.453100e-17     0.9641    26.1100\n",
       "33    LAE  4198.0  4.673800e-17     0.0844   325.5400\n",
       "...   ...     ...           ...        ...        ...\n",
       "5402  LAE  4070.3  1.396600e-16    24.5670     3.1416\n",
       "5403  LAE  4065.1  6.215900e-17     0.6154    55.6750\n",
       "5404  LAE  3900.6  7.877400e-17     1.8786    21.2810\n",
       "5405  LAE  4124.9  6.791500e-17     0.3966    97.1920\n",
       "5406  LAE  4105.0  4.936500e-17     0.3407    81.4410\n",
       "5407  LAE  3896.7  7.009800e-17     0.4997    71.0520\n",
       "5408  LAE  3843.5  1.373600e-16     0.3806   177.8400\n",
       "5409  LAE  3887.2  5.153400e-17     1.6826    15.4370\n",
       "5410  LAE  3967.3  5.680200e-17    11.1750     2.6688\n",
       "5411  LAE  4018.4  5.415700e-17     0.8258    35.3240\n",
       "5412  LAE  4146.8  4.966200e-17     0.5211    54.6650\n",
       "5413  LAE  4187.9  9.293900e-17     0.2335   232.8600\n",
       "5414  LAE  4146.9  1.470100e-16     1.4795    56.9970\n",
       "5415  LAE  4015.7  6.017200e-17     0.1330   243.3600\n",
       "5417  LAE  4107.2  4.684900e-17     4.3242     6.0964\n",
       "5418  LAE  3878.2  5.799600e-17     0.2097   138.7500\n",
       "5419  LAE  3869.7  6.951100e-17     0.6678    51.9930\n",
       "5420  LAE  3858.3  6.826700e-17     0.5225    64.8770\n",
       "5421  LAE  3857.1  1.154500e-16     0.2333   245.5800\n",
       "5422  LAE  4110.7  6.597700e-17     0.4399    84.5350\n",
       "5423  LAE  4053.9  5.354400e-17     2.1974    13.3580\n",
       "5424  LAE  4066.4  9.140900e-17     0.1427   353.3200\n",
       "5425  LAE  4173.2  7.573800e-17     0.1504   292.5300\n",
       "5426  LAE  3912.9  1.425700e-16     0.3022   240.9400\n",
       "5427  LAE  4076.2  9.316900e-17     0.1486   347.4800\n",
       "5428  LAE  4084.3  1.491600e-16     1.7091    48.5620\n",
       "5430  LAE  3996.2  2.032800e-16     0.4872   222.2600\n",
       "5432  LAE  3852.6  1.113900e-16     0.7407    74.4530\n",
       "5434  LAE  3841.8  1.190700e-16     1.7287    33.9100\n",
       "5435  LAE  4081.4  7.338600e-17     1.1131    36.6330\n",
       "\n",
       "[4415 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('type').get_group('LAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>wl</th>\n",
       "      <th>el</th>\n",
       "      <th>cont_flux</th>\n",
       "      <th>ew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OII</td>\n",
       "      <td>3896.6</td>\n",
       "      <td>5.990100e-16</td>\n",
       "      <td>18.7050</td>\n",
       "      <td>16.2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OII</td>\n",
       "      <td>4108.6</td>\n",
       "      <td>1.456500e-15</td>\n",
       "      <td>284.1400</td>\n",
       "      <td>2.8862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OII</td>\n",
       "      <td>4098.2</td>\n",
       "      <td>2.862100e-15</td>\n",
       "      <td>205.8200</td>\n",
       "      <td>7.7904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OII</td>\n",
       "      <td>3850.3</td>\n",
       "      <td>1.492100e-16</td>\n",
       "      <td>10.0580</td>\n",
       "      <td>7.3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OII</td>\n",
       "      <td>4026.2</td>\n",
       "      <td>1.092200e-16</td>\n",
       "      <td>1308.8000</td>\n",
       "      <td>0.0451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OII</td>\n",
       "      <td>4110.7</td>\n",
       "      <td>2.015200e-15</td>\n",
       "      <td>256.6200</td>\n",
       "      <td>4.4264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>OII</td>\n",
       "      <td>4121.6</td>\n",
       "      <td>5.543600e-16</td>\n",
       "      <td>226.8100</td>\n",
       "      <td>1.3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>OII</td>\n",
       "      <td>4166.7</td>\n",
       "      <td>2.258100e-16</td>\n",
       "      <td>6.4281</td>\n",
       "      <td>20.3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>OII</td>\n",
       "      <td>4195.0</td>\n",
       "      <td>3.691600e-15</td>\n",
       "      <td>94.5930</td>\n",
       "      <td>22.9090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>OII</td>\n",
       "      <td>4152.8</td>\n",
       "      <td>6.126700e-16</td>\n",
       "      <td>59.0750</td>\n",
       "      <td>5.9659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>OII</td>\n",
       "      <td>3980.5</td>\n",
       "      <td>2.278200e-16</td>\n",
       "      <td>21.5140</td>\n",
       "      <td>5.5966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>OII</td>\n",
       "      <td>3968.5</td>\n",
       "      <td>1.070300e-15</td>\n",
       "      <td>151.4400</td>\n",
       "      <td>3.7127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>OII</td>\n",
       "      <td>4001.8</td>\n",
       "      <td>2.831400e-16</td>\n",
       "      <td>109.0300</td>\n",
       "      <td>1.3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>OII</td>\n",
       "      <td>3996.7</td>\n",
       "      <td>4.075700e-16</td>\n",
       "      <td>256.0900</td>\n",
       "      <td>0.8480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>OII</td>\n",
       "      <td>4105.9</td>\n",
       "      <td>2.045700e-16</td>\n",
       "      <td>18.9090</td>\n",
       "      <td>6.0838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>OII</td>\n",
       "      <td>3867.1</td>\n",
       "      <td>9.704700e-15</td>\n",
       "      <td>13739.0000</td>\n",
       "      <td>0.3524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>OII</td>\n",
       "      <td>4024.3</td>\n",
       "      <td>1.692800e-16</td>\n",
       "      <td>6.5514</td>\n",
       "      <td>13.9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>OII</td>\n",
       "      <td>4180.2</td>\n",
       "      <td>1.036900e-16</td>\n",
       "      <td>14.1230</td>\n",
       "      <td>4.2793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>OII</td>\n",
       "      <td>4154.4</td>\n",
       "      <td>1.325900e-16</td>\n",
       "      <td>17.0660</td>\n",
       "      <td>4.4728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>OII</td>\n",
       "      <td>4099.1</td>\n",
       "      <td>4.794000e-15</td>\n",
       "      <td>1030.6000</td>\n",
       "      <td>2.6072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>OII</td>\n",
       "      <td>4107.4</td>\n",
       "      <td>7.043500e-17</td>\n",
       "      <td>6.2940</td>\n",
       "      <td>6.2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>OII</td>\n",
       "      <td>3862.2</td>\n",
       "      <td>1.312700e-14</td>\n",
       "      <td>3617.0000</td>\n",
       "      <td>1.8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>OII</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>9.911100e-16</td>\n",
       "      <td>1859.7000</td>\n",
       "      <td>0.3117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>OII</td>\n",
       "      <td>4191.3</td>\n",
       "      <td>6.677100e-17</td>\n",
       "      <td>10.0490</td>\n",
       "      <td>3.8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>OII</td>\n",
       "      <td>4091.9</td>\n",
       "      <td>4.586200e-16</td>\n",
       "      <td>85.1760</td>\n",
       "      <td>3.0072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>OII</td>\n",
       "      <td>4195.4</td>\n",
       "      <td>4.715900e-17</td>\n",
       "      <td>1.4160</td>\n",
       "      <td>19.5540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>OII</td>\n",
       "      <td>4193.7</td>\n",
       "      <td>3.320400e-16</td>\n",
       "      <td>4.1325</td>\n",
       "      <td>47.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>OII</td>\n",
       "      <td>4087.9</td>\n",
       "      <td>5.255300e-17</td>\n",
       "      <td>10.1100</td>\n",
       "      <td>2.8974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>OII</td>\n",
       "      <td>3938.7</td>\n",
       "      <td>1.040800e-15</td>\n",
       "      <td>201.7400</td>\n",
       "      <td>2.6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>OII</td>\n",
       "      <td>4165.1</td>\n",
       "      <td>5.786200e-17</td>\n",
       "      <td>20.8180</td>\n",
       "      <td>1.6084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5227</th>\n",
       "      <td>OII</td>\n",
       "      <td>4036.9</td>\n",
       "      <td>5.272500e-16</td>\n",
       "      <td>51.2070</td>\n",
       "      <td>5.5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>OII</td>\n",
       "      <td>4164.7</td>\n",
       "      <td>9.339000e-16</td>\n",
       "      <td>40.7010</td>\n",
       "      <td>13.2760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>OII</td>\n",
       "      <td>4146.0</td>\n",
       "      <td>1.677500e-16</td>\n",
       "      <td>14.1650</td>\n",
       "      <td>6.7899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>OII</td>\n",
       "      <td>4070.0</td>\n",
       "      <td>9.530200e-16</td>\n",
       "      <td>421.9500</td>\n",
       "      <td>1.2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>OII</td>\n",
       "      <td>4172.6</td>\n",
       "      <td>1.473500e-15</td>\n",
       "      <td>306.8000</td>\n",
       "      <td>2.7893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>OII</td>\n",
       "      <td>4021.5</td>\n",
       "      <td>5.943700e-17</td>\n",
       "      <td>1.2213</td>\n",
       "      <td>26.2530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>OII</td>\n",
       "      <td>4150.2</td>\n",
       "      <td>4.762400e-17</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>36.8270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>OII</td>\n",
       "      <td>4101.4</td>\n",
       "      <td>1.643900e-16</td>\n",
       "      <td>8.6489</td>\n",
       "      <td>10.6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>OII</td>\n",
       "      <td>4157.2</td>\n",
       "      <td>4.296000e-16</td>\n",
       "      <td>43.2700</td>\n",
       "      <td>5.7234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>OII</td>\n",
       "      <td>3956.8</td>\n",
       "      <td>1.448700e-16</td>\n",
       "      <td>50.9890</td>\n",
       "      <td>1.4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>OII</td>\n",
       "      <td>4107.3</td>\n",
       "      <td>1.767600e-16</td>\n",
       "      <td>6.3565</td>\n",
       "      <td>15.6480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>OII</td>\n",
       "      <td>4132.3</td>\n",
       "      <td>2.208200e-15</td>\n",
       "      <td>52.0840</td>\n",
       "      <td>24.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>OII</td>\n",
       "      <td>3985.4</td>\n",
       "      <td>2.945400e-16</td>\n",
       "      <td>43.4740</td>\n",
       "      <td>3.5895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>OII</td>\n",
       "      <td>3923.5</td>\n",
       "      <td>2.026500e-15</td>\n",
       "      <td>1192.3000</td>\n",
       "      <td>0.8728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>OII</td>\n",
       "      <td>4141.5</td>\n",
       "      <td>1.377000e-16</td>\n",
       "      <td>6.4129</td>\n",
       "      <td>12.2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332</th>\n",
       "      <td>OII</td>\n",
       "      <td>4038.9</td>\n",
       "      <td>6.429500e-16</td>\n",
       "      <td>40.4170</td>\n",
       "      <td>8.6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>OII</td>\n",
       "      <td>4093.4</td>\n",
       "      <td>1.621900e-16</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>1.1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>OII</td>\n",
       "      <td>4169.8</td>\n",
       "      <td>2.119600e-15</td>\n",
       "      <td>625.5900</td>\n",
       "      <td>1.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>OII</td>\n",
       "      <td>4129.2</td>\n",
       "      <td>7.443700e-17</td>\n",
       "      <td>333.0600</td>\n",
       "      <td>0.1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>OII</td>\n",
       "      <td>4037.2</td>\n",
       "      <td>8.382700e-17</td>\n",
       "      <td>14.5590</td>\n",
       "      <td>3.1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>OII</td>\n",
       "      <td>3889.9</td>\n",
       "      <td>1.130500e-15</td>\n",
       "      <td>202.6300</td>\n",
       "      <td>2.8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>OII</td>\n",
       "      <td>4032.1</td>\n",
       "      <td>5.514900e-17</td>\n",
       "      <td>96.6790</td>\n",
       "      <td>0.3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>OII</td>\n",
       "      <td>4163.9</td>\n",
       "      <td>2.036400e-16</td>\n",
       "      <td>51.4970</td>\n",
       "      <td>2.2870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>OII</td>\n",
       "      <td>4102.9</td>\n",
       "      <td>6.714400e-17</td>\n",
       "      <td>4.7401</td>\n",
       "      <td>7.9538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>OII</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>9.221900e-17</td>\n",
       "      <td>21.5480</td>\n",
       "      <td>2.1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>OII</td>\n",
       "      <td>4170.9</td>\n",
       "      <td>3.551700e-16</td>\n",
       "      <td>20.5060</td>\n",
       "      <td>10.0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>OII</td>\n",
       "      <td>3978.5</td>\n",
       "      <td>1.762500e-15</td>\n",
       "      <td>1897.4000</td>\n",
       "      <td>0.4904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>OII</td>\n",
       "      <td>4190.5</td>\n",
       "      <td>1.204700e-16</td>\n",
       "      <td>150.6400</td>\n",
       "      <td>0.4684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>OII</td>\n",
       "      <td>4111.4</td>\n",
       "      <td>3.253500e-16</td>\n",
       "      <td>57.8050</td>\n",
       "      <td>3.1736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>OII</td>\n",
       "      <td>4187.5</td>\n",
       "      <td>9.931600e-16</td>\n",
       "      <td>124.7100</td>\n",
       "      <td>4.6581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type      wl            el   cont_flux       ew\n",
       "5     OII  3896.6  5.990100e-16     18.7050  16.2200\n",
       "6     OII  4108.6  1.456500e-15    284.1400   2.8862\n",
       "7     OII  4098.2  2.862100e-15    205.8200   7.7904\n",
       "10    OII  3850.3  1.492100e-16     10.0580   7.3358\n",
       "39    OII  4026.2  1.092200e-16   1308.8000   0.0451\n",
       "41    OII  4110.7  2.015200e-15    256.6200   4.4264\n",
       "52    OII  4121.6  5.543600e-16    226.8100   1.3850\n",
       "54    OII  4166.7  2.258100e-16      6.4281  20.3430\n",
       "57    OII  4195.0  3.691600e-15     94.5930  22.9090\n",
       "60    OII  4152.8  6.126700e-16     59.0750   5.9659\n",
       "64    OII  3980.5  2.278200e-16     21.5140   5.5966\n",
       "79    OII  3968.5  1.070300e-15    151.4400   3.7127\n",
       "83    OII  4001.8  2.831400e-16    109.0300   1.3873\n",
       "91    OII  3996.7  4.075700e-16    256.0900   0.8480\n",
       "97    OII  4105.9  2.045700e-16     18.9090   6.0838\n",
       "100   OII  3867.1  9.704700e-15  13739.0000   0.3524\n",
       "107   OII  4024.3  1.692800e-16      6.5514  13.9590\n",
       "109   OII  4180.2  1.036900e-16     14.1230   4.2793\n",
       "111   OII  4154.4  1.325900e-16     17.0660   4.4728\n",
       "112   OII  4099.1  4.794000e-15   1030.6000   2.6072\n",
       "120   OII  4107.4  7.043500e-17      6.2940   6.2977\n",
       "121   OII  3862.2  1.312700e-14   3617.0000   1.8058\n",
       "123   OII  4187.0  9.911100e-16   1859.7000   0.3117\n",
       "129   OII  4191.3  6.677100e-17     10.0490   3.8935\n",
       "147   OII  4091.9  4.586200e-16     85.1760   3.0072\n",
       "158   OII  4195.4  4.715900e-17      1.4160  19.5540\n",
       "160   OII  4193.7  3.320400e-16      4.1325  47.1370\n",
       "169   OII  4087.9  5.255300e-17     10.1100   2.8974\n",
       "172   OII  3938.7  1.040800e-15    201.7400   2.6696\n",
       "182   OII  4165.1  5.786200e-17     20.8180   1.6084\n",
       "...   ...     ...           ...         ...      ...\n",
       "5227  OII  4036.9  5.272500e-16     51.2070   5.5970\n",
       "5232  OII  4164.7  9.339000e-16     40.7010  13.2760\n",
       "5235  OII  4146.0  1.677500e-16     14.1650   6.7899\n",
       "5236  OII  4070.0  9.530200e-16    421.9500   1.2480\n",
       "5237  OII  4172.6  1.473500e-15    306.8000   2.7893\n",
       "5253  OII  4021.5  5.943700e-17      1.2213  26.2530\n",
       "5257  OII  4150.2  4.762400e-17      0.7430  36.8270\n",
       "5263  OII  4101.4  1.643900e-16      8.6489  10.6650\n",
       "5264  OII  4157.2  4.296000e-16     43.2700   5.7234\n",
       "5267  OII  3956.8  1.448700e-16     50.9890   1.4837\n",
       "5280  OII  4107.3  1.767600e-16      6.3565  15.6480\n",
       "5284  OII  4132.3  2.208200e-15     52.0840  24.1490\n",
       "5286  OII  3985.4  2.945400e-16     43.4740   3.5895\n",
       "5301  OII  3923.5  2.026500e-15   1192.3000   0.8728\n",
       "5318  OII  4141.5  1.377000e-16      6.4129  12.2850\n",
       "5332  OII  4038.9  6.429500e-16     40.4170   8.6563\n",
       "5338  OII  4093.4  1.621900e-16     76.9600   1.1779\n",
       "5339  OII  4169.8  2.119600e-15    625.5900   1.9650\n",
       "5354  OII  4129.2  7.443700e-17    333.0600   0.1271\n",
       "5364  OII  4037.2  8.382700e-17     14.5590   3.1304\n",
       "5375  OII  3889.9  1.130500e-15    202.6300   2.8160\n",
       "5385  OII  4032.1  5.514900e-17     96.6790   0.3094\n",
       "5389  OII  4163.9  2.036400e-16     51.4970   2.2870\n",
       "5395  OII  4102.9  6.714400e-17      4.7401   7.9538\n",
       "5399  OII  3893.0  9.221900e-17     21.5480   2.1635\n",
       "5400  OII  4170.9  3.551700e-16     20.5060  10.0510\n",
       "5416  OII  3978.5  1.762500e-15   1897.4000   0.4904\n",
       "5429  OII  4190.5  1.204700e-16    150.6400   0.4684\n",
       "5431  OII  4111.4  3.253500e-16     57.8050   3.1736\n",
       "5433  OII  4187.5  9.931600e-16    124.7100   4.6581\n",
       "\n",
       "[1021 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('type').get_group('OII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               wl            el   cont_flux          ew\n",
      "type                                                   \n",
      "LAE   4003.127475  8.005258e-17    3.095571  540.767356\n",
      "OII   4066.480705  9.581660e-16  352.315656    7.752076\n",
      "              wl            el    cont_flux           ew\n",
      "type                                                    \n",
      "LAE   112.761281  3.630592e-17    58.841667  3713.490362\n",
      "OII    95.303749  2.219254e-15  1943.049897     8.049062\n"
     ]
    }
   ],
   "source": [
    "groups = dataset.groupby('type')\n",
    "print(groups.mean())\n",
    "print(groups.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5342, 5)\n"
     ]
    }
   ],
   "source": [
    "for col in dataset.columns:\n",
    "    if dataset[col].dtypes != object:\n",
    "        mask = ((dataset[col] > (dataset[col].mean() - 3*dataset[col].std())) &\n",
    "                (dataset[col] < (dataset[col].mean() + 3*dataset[col].std())))\n",
    "        dataset = dataset[mask]\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform pandas data frame into a numpy array that can be fed to sklearn methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = dataset.values\n",
    "m, n = data_array.shape\n",
    "for j in range(1, n):\n",
    "    mean, std = np.mean(data_array[:, j]), np.std(data_array[:, j])\n",
    "    for i in range(0, m):\n",
    "        data_array[i, j] = (data_array[i, j] - mean)/std\n",
    "X = data_array[:,1:5].astype('float64')\n",
    "y = data_array[:,0]\n",
    "for i in range(y.shape[0]):\n",
    "    y[i] = 0 if y[i] == 'LAE' else 1\n",
    "y = y.astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick way to see what variables are important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple linear model and use the cofficients of different variables to track variables' importance. Useful when there are many and we want to get rid of some of them, or to just build understanding of the model. Note that this doesn't properly inform one of which variables are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9326473339569691\n",
      "[[  0.85205645   4.89282801   3.95209011 -11.53416063]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LRmodel = LogisticRegression()\n",
    "LRmodel.fit(X_train, y_train)\n",
    "print(LRmodel.score(X_test, y_test))\n",
    "LRmodel.fit(X, y)\n",
    "print(LRmodel.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First steps with models: Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are nice because they can be interpreted easily. For example, this is a decision tree showing how scientists might decide whether a newly found planet has a good chance to harbor life:\n",
    "\n",
    "Figure from [here](http://www.machinelearningtutorial.net/2017/01/17/decisiontree/).\n",
    "\n",
    "<br><div style=\"text-align: center \">  <b> IS ANYBODY OUT THERE?</b></div>\n",
    "\n",
    "<img src=\"Strata_images/exoplanets.svg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees work by deciding where to split the data set using values of different features, and where to stop.\n",
    "\n",
    "Mathematically, a good decision tree is one that maximizes the information gain (e.g. the increase in accuracy) at every \"split\".\n",
    "\n",
    "<b> Pros </b> Easy to interpret, fast.\n",
    "\n",
    "<b> Cons </b> Prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get coding!\n",
    "\n",
    "-  Import model, fit using k-fold (k = 5) cross validation, establish benchmark performance.\n",
    "\n",
    "-  Consider the metric and its potential fallbacks by comparing to \"dummy\" estimator;\n",
    "\n",
    "-  Calculate and plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9296149924848383 0.008725745500461913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "scores = []\n",
    "for train, test in kf.split(X):\n",
    "    X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree.fit(X_train, y_train)\n",
    "    scores.append(tree.score(X_test, y_test))\n",
    "print(np.array(scores).mean(), np.array(scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Metrics</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "0.8214285714285714 0.8313253012048193 0.9456928838951311\n",
      "Dummy:\n",
      "1.0 0.15730337078651685 0.15730337078651685\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree.predict(X_test)\n",
    "y_pred_dummy = np.ones(y_test.shape[0]).astype('int')\n",
    "print('Prediction:')\n",
    "print(metrics.recall_score(y_test, y_pred), \n",
    "      metrics.precision_score(y_test, y_pred), \n",
    "      metrics.accuracy_score(y_test, y_pred))\n",
    "print('Dummy:')\n",
    "print(metrics.recall_score(y_test, y_pred_dummy), \n",
    "      metrics.precision_score(y_test, y_pred_dummy), \n",
    "      metrics.accuracy_score(y_test, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[872  28]\n",
      " [ 30 138]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(conf_matrix, ['LAE', 'OII'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another easy to interpret algorithm is KNN (K nearest neighbors). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center \">  <b> LET'S FIND SOME NEIGHBORS!</b></div>\n",
    "<table><tr>\n",
    "<td> <img src=\"Strata_images/KNN_1.png\" width=\"350\"/> </td>\n",
    "<td>  <img src=\"Strata_images/KNN_2.png\" width=\"350\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get coding!\n",
    "\n",
    "Import model, fit using k-fold (k = 5) cross validation, establish benchmark performance, play with basic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9414082565143739 0.002513185406916173\n",
      "0.7812166488794023 0.8905109489051095 0.9447772369898915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "knn = KNeighborsClassifier(p=1, leaf_size=10, n_neighbors=10, weights='distance')\n",
    "cross_val = cross_val_score(knn, X, y)\n",
    "print(cross_val.mean(), cross_val.std())\n",
    "y_pred = cross_val_predict(knn, X, y, cv=kf)\n",
    "print(metrics.recall_score(y, y_pred), \n",
    "      metrics.precision_score(y, y_pred), \n",
    "      metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and 10-minute break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Advanced Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines are a long-term staple of machine learning. Parameter tuning is very important in SVMs, and it's the curse and blessing of this algorithm.\n",
    "\n",
    "<b>Pros: </b> Accurate, Powerful\n",
    "\n",
    "<b>Cons: </b>  SLOW, need standardization\n",
    "\n",
    "It's usually a good idea to do parameter optimization on a (representative) selection of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMs in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a classification problem such as this one, SVMs attempts to find the ideal boundary to separate the two classes.\n",
    "\n",
    "<img src=\"Strata_images/SVM_1.png\" width=\"300\"/>\n",
    "\n",
    "This looks easy, but even in this simple cases of completely separable variables, there are many possible choices, with different resulting boundaries.\n",
    "\n",
    "<img src=\"Strata_images/SVM_2.png\" width=\"300\"/> \n",
    "\n",
    "SVM's strategy is to 1. Maximize the separation between classes, called the <b> margin </b> and 2. Use slack variables to attribute a \"penalty\" to misclassifications (soft margin).\n",
    "\n",
    "<img src=\"Strata_images/SVM_3.png\" width=\"300\"/>\n",
    "\n",
    "In the more general case of non-linearly-separable variables, SVMs attempt to map the original feature space (for us a 4D space) to a higher dimensionality space, where instances are more separable. The set of functions used for the mapping is called <b>kernel</b>. \n",
    "<br>\n",
    "<br>\n",
    "<img src=\"Strata_images/SVM_4.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "The most important parameters of an SVM are:\n",
    "\n",
    "- The type of kernel (linear, polynomial, or Gaussian, \"rbf\" in sklearn);\n",
    "\n",
    "<img src=\"Strata_images/SVM_5.png\" width=\"400\"/>\n",
    "\n",
    "- Gamma, the \"wiggliness\" of the boundary (small gammas = more linear);\n",
    "\n",
    "<img src=\"Strata_images/SVM_6.png\" width=\"300\"/>\n",
    "\n",
    "- C, the soft margin parameter (smaller C values assign a smaller penalty to misclassifications near the boundary, and generates a wider margin).\n",
    "\n",
    "<img src=\"Strata_images/SVM_7.png\" width=\"300\"/>\n",
    "\n",
    "All the figures in this section are from [here](https://www.ncbi.nlm.nih.gov/pubmed/20221922) and [here](https://www.cs.utexas.edu/~mooney/cs391L/slides/svm.ppt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get coding! \n",
    "\n",
    "-  Import model;\n",
    "\n",
    "-  Establish benchmark performance for 5 fold cross validation;\n",
    "\n",
    "-  Visualize and briefly describe the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9414082565143739 0.002513185406916173\n",
      "0.7812166488794023 0.8905109489051095 0.9447772369898915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svmachine = SVC()\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "cross_val = cross_val_score(knn, X, y)\n",
    "print(cross_val.mean(), cross_val.std())\n",
    "y_pred = cross_val_predict(knn, X, y, cv=kf)\n",
    "print(metrics.recall_score(y, y_pred), \n",
    "      metrics.precision_score(y, y_pred), \n",
    "      metrics.accuracy_score(y, y_pred))\n",
    "svmachine.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TASKS (10-15 mins) </b>\n",
    "\n",
    "-  Play with different parameters, such as type of kernel (for time scaling reasons, use only poly and rbf), soft margin C, and gamma, to see if you can beat the benchmark performance above. Tip 1: Trying 2-3 values per parameter will be sufficient for now, especially if your machine is taking long. Tip 2: Use low values of gamma (< 1.0) to reduce fitting time.\n",
    "\n",
    "-  Now do the same thing, but using precision as your scoring method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['linear'], 'C': [1, 10, 100]}, {'kernel': ['rbf'], 'gamma': [0.01, 0.1], 'C': [1, 10, 100]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_parameters = [{'kernel': ['linear'], 'C': [1, 10, 100]}, \n",
    "                    {'kernel': ['rbf'], 'gamma': [1.e-2, 1.e-1], 'C': [1, 10, 100]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=kf, scoring='accuracy')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1331099298265245\n",
      "[0.93579184 0.94384126 0.94964433 0.9107076  0.93260951 0.93055036\n",
      " 0.9419693  0.94122052 0.94608761]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.cv_results_['mean_fit_time'].mean())\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92918028 0.91856683 0.89876615 0.98195672 0.94478335 0.94238222\n",
      " 0.92070368 0.92605969 0.91577064]\n",
      "{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=kf, scoring='precision')\n",
    "clf.fit(X, y)\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coding Solution.\n",
    "\n",
    "Introduce Grid Search CV (params, cv, scoring, verbose, n_jobs) as a method to optimize various parameters simultaneously; use timings to get an idea of the speed of various methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Summary\n",
    "\n",
    "-  After parameter optimization, SVM's performance improves a bit over the baseline.\n",
    "\n",
    "-  We learned how to optimize parameters with Grid Search.\n",
    "\n",
    "-  The best model depends A LOT on the metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods: 1. Random Forest Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifiers are combinations of decision trees. The \"random\" part refers to the fact that different trees in the forest are created using random splits of the data, and random subsets of the features. This randomization process makes the algorithm more robust against overfitting, compared to single trees.\n",
    "\n",
    "<b> Pros: </b> Fast (parallel), robust, insensitive to data range.\n",
    "\n",
    "<b> Cons: </b> Fast but not fastest when compared to other ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests have many adjustable parameters. One can tune the parameters of each tree, and the way they are combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Strata_images/DT1.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Parameters\n",
    "\n",
    "The figure above shows an example of possible split. The parameters associated to that are:\n",
    "\n",
    "-  The minimum number of instances in a leaf node;\n",
    "\n",
    "-  The minimum number of instances required in a split node;\n",
    "\n",
    "- The maximum depth of tree.\n",
    "\n",
    "They all deal with reducing overfitting by avoiding to go \"too deep\" in each tree; it makes sense to change two out of three.\n",
    "\n",
    "Additional parameters are:\n",
    "\n",
    "-  The criterion chosen to decide whether a split is \"worth it\", expressed in terms of information gain;\n",
    "\n",
    "-  The number of features that are used in building trees.\n",
    "\n",
    "#### Forest Parameters\n",
    "\n",
    "In Random Forests, the predictions generated by all the trees are simply averaged to produce the final results. The number of trees in the forest can be adjusted, with the general understanding that more trees are better, but at some point performance will plateau, so one can find the trade-off between having more trees and lower runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get coding! \n",
    "\n",
    "-  Import model;\n",
    "\n",
    "-  Establish benchmark performance for 5 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445894651887161 0.005610941671953568\n",
      "0.80042689434365 0.8581235697940504 0.9417821040808686\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "cross_val = cross_val_score(rfc, X, y)\n",
    "print(cross_val.mean(), cross_val.std())\n",
    "y_pred = cross_val_predict(rfc, X, y, cv=kf)\n",
    "print(metrics.recall_score(y, y_pred), \n",
    "      metrics.precision_score(y, y_pred), \n",
    "      metrics.accuracy_score(y, y_pred))\n",
    "print(rfc.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TASKS (10-15 minutes) </b> \n",
    "\n",
    "-  Use the get_params() method to find out the names and signatures of different parameters, and their default values.\n",
    "\n",
    "-  Play with different values of the number of trees (estimators, using values between 5 and 50), maximum depth of tree (usually around 3-8), the minimum amount of instances in a split (2-10), and the maximum number of features (you can decide this one!) allowed in builiding individual trees to see if you can beat the benchmark performance above.\n",
    "\n",
    "-  Now do the same thing, but using recall as your scoring method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34332081167786205\n",
      "[0.94365406 0.9462748  0.94721078 0.9462748  0.94440285 0.94459004\n",
      " 0.946462   0.94552602 0.94028454 0.94346687 0.94384126 0.94590041\n",
      " 0.9462748  0.94721078 0.94721078 0.94777237 0.94477724 0.94608761\n",
      " 0.9462748  0.94833396 0.9462748  0.94777237 0.94795957 0.94777237\n",
      " 0.94477724 0.94533882 0.94833396 0.94833396 0.94758517 0.94721078\n",
      " 0.94702359 0.94702359 0.94777237 0.94833396 0.94777237 0.94739798\n",
      " 0.94795957 0.94739798 0.94795957 0.94683639 0.94683639 0.94683639\n",
      " 0.94721078 0.9462748  0.94739798 0.94702359 0.94552602 0.9466492\n",
      " 0.94777237 0.94608761 0.94758517 0.94702359 0.94814676 0.94702359\n",
      " 0.94833396 0.946462   0.94739798 0.94608761 0.94590041 0.94758517\n",
      " 0.94777237 0.94795957 0.94795957 0.94721078 0.94795957 0.94721078\n",
      " 0.9466492  0.94552602 0.94440285 0.94608761 0.94590041 0.946462\n",
      " 0.94365406 0.94608761 0.94758517 0.94590041 0.94608761 0.94758517\n",
      " 0.946462   0.94683639 0.94384126 0.94758517 0.94515163 0.94758517\n",
      " 0.94047173 0.94683639 0.94721078 0.94365406 0.9372894  0.94608761\n",
      " 0.94702359 0.94852115 0.9466492  0.9466492  0.94739798 0.94870835\n",
      " 0.94496443 0.94365406 0.94590041 0.94777237 0.94327967 0.94496443\n",
      " 0.94402845 0.9466492  0.9466492  0.94590041 0.94777237 0.94758517]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8,\n",
       " 'max_features': 3,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'n_estimators': list(np.linspace(5,50,4).astype('int')),\n",
    "                    'max_depth': [3, 5, 8],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'max_features': list(range(2, 5))}]\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=kf, scoring='accuracy', n_jobs=4)\n",
    "clf.fit(X, y)\n",
    "print(clf.cv_results_['mean_fit_time'].mean())\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3344103089085331\n",
      "[0.80785894 0.82815811 0.83671106 0.83456344 0.83137016 0.82175278\n",
      " 0.82817218 0.8324252  0.83245335 0.82280783 0.83564194 0.8335037\n",
      " 0.85271499 0.83458689 0.83671106 0.83456813 0.81537091 0.83990903\n",
      " 0.83670167 0.83349432 0.82598234 0.83137016 0.82817687 0.82817687\n",
      " 0.82709837 0.84522178 0.84414328 0.84630028 0.84738347 0.83885398\n",
      " 0.83775203 0.84950295 0.83777079 0.84419019 0.83988557 0.83882115\n",
      " 0.83028227 0.81855012 0.83030104 0.83028696 0.83671106 0.83029166\n",
      " 0.83137016 0.82494606 0.83455875 0.82067428 0.82920846 0.83030104\n",
      " 0.84204257 0.83562317 0.83989026 0.83457282 0.83240644 0.82923661\n",
      " 0.83456813 0.83882584 0.83668291 0.84416674 0.83669698 0.83349432\n",
      " 0.83346617 0.83669229 0.84418081 0.83457282 0.8420285  0.82281252\n",
      " 0.83563256 0.84417612 0.82922254 0.83777079 0.83670167 0.84097815\n",
      " 0.82495075 0.83240175 0.82921785 0.83774265 0.8335037  0.83561848\n",
      " 0.82601987 0.83348494 0.82497421 0.82920846 0.8452124  0.83455406\n",
      " 0.8217434  0.8420285  0.83243458 0.84095938 0.82389571 0.83348025\n",
      " 0.83347555 0.83240644 0.83667353 0.84204257 0.84630028 0.83777079\n",
      " 0.8313467  0.82389102 0.84843852 0.83348494 0.83241582 0.83561379\n",
      " 0.84949826 0.83882584 0.82170587 0.83671106 0.82601987 0.83563256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'max_features': 3, 'min_samples_split': 2, 'n_estimators': 5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=kf, scoring='recall', n_jobs=4)\n",
    "clf.fit(X, y)\n",
    "print(clf.cv_results_['mean_fit_time'].mean())\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods 2: Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting models are another ensemble method where different decision trees are combined together.\n",
    "\n",
    "Unlike Random Forests, the model is built by <b> adding individual trees in a sequential fashion, </b>\n",
    "but choosing which trees we add to the model in a way that minimizes the current loss function. The \"Gradient\" part refers to the fact that we try to move along the gradient of the objective function (by calculating its numerical derivative) as we add more trees.\n",
    "\n",
    "The parameters depend on the particular implementation.\n",
    "\n",
    "In the sklearn formulation, the parameters of each tree are essentially the same we saw above; additionally we have the \"learning_rate\" parameter, which dictates how much each tree contribute to the final estimator, and the \"subsample\" parameters, which allows one to use a < 1.0 fraction of samples.\n",
    "\n",
    "I liked this blog post about parameter tuning for GBMs:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll do the usual import and benchmarking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946836656199952 0.001045360969511496\n",
      "0.8495197438633938 0.8549946294307197 0.948333957319356\n",
      "{'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'presort': 'auto', 'random_state': None, 'subsample': 1.0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "cross_val = cross_val_score(gbc, X, y)\n",
    "print(cross_val.mean(), cross_val.std())\n",
    "y_pred = cross_val_predict(gbc, X, y, cv=kf)\n",
    "print(metrics.recall_score(y, y_pred), \n",
    "      metrics.precision_score(y, y_pred), \n",
    "      metrics.accuracy_score(y, y_pred))\n",
    "print(gbc.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TASKS (10 minutes) </b>\n",
    "\n",
    "-  Use the get_params() method to find out the names and signatures of different parameters, and their default values.\n",
    "\n",
    "-  Play with different values of the number of trees (estimators: 5, 10, 20), max depth of tree (2-8), learning rate (0.1-0.5), and the maximum number of features allowed to see how much you can improve the benchmark performance above.\n",
    "\n",
    "-  Compare the timings to Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1509698027656192\n",
      "[0.38216735 0.64035919 0.80465627 0.54960141 0.6820079  0.80145361\n",
      " 0.58158114 0.64998126 0.80252742 0.43422108 0.67344088 0.81962393\n",
      " 0.54435903 0.70545813 0.82283128 0.52289691 0.76092093 0.83563256\n",
      " 0.52188878 0.72466942 0.81536153 0.53356464 0.74277407 0.81535684\n",
      " 0.51331238 0.74489354 0.82174809 0.54426521 0.73743317 0.81534745\n",
      " 0.53364439 0.7310513  0.817481   0.53580139 0.75557065 0.8121401\n",
      " 0.56885493 0.73635936 0.81643065 0.5368236  0.75023913 0.81964738\n",
      " 0.55494232 0.75557065 0.8132186  0.55069399 0.75130825 0.81960516\n",
      " 0.57738442 0.7491794  0.82174809 0.57527433 0.75774642 0.81747631\n",
      " 0.57526495 0.74916532 0.81749038 0.59446216 0.75346525 0.81642595\n",
      " 0.59554536 0.75667261 0.81536622 0.71288567 0.79826033 0.82279845\n",
      " 0.66915033 0.80573946 0.82601518 0.68947765 0.80359654 0.82922254\n",
      " 0.72789554 0.81534276 0.84204727 0.76414705 0.83030104 0.8484479\n",
      " 0.77692487 0.8313467  0.84310231 0.74278345 0.81642126 0.82817218\n",
      " 0.74493107 0.819638   0.84201912 0.76518333 0.82708899 0.83991841\n",
      " 0.75236799 0.82284536 0.83137954 0.75238206 0.82175747 0.83776141\n",
      " 0.76516457 0.81214948 0.83349901 0.76195252 0.80786832 0.83777079\n",
      " 0.76838131 0.81319514 0.82921315 0.77690611 0.82067897 0.83137016\n",
      " 0.76304979 0.82388633 0.84414797 0.75560349 0.82073057 0.83883053\n",
      " 0.77800806 0.82815811 0.83029635 0.75987058 0.81640719 0.8462909\n",
      " 0.76947857 0.81425957 0.83669698 0.7844087  0.81642595 0.83565601\n",
      " 0.80784017 0.81959578 0.83455875 0.80148175 0.81857357 0.83135608\n",
      " 0.80998779 0.81857357 0.83029635 0.79404015 0.83989026 0.83030573\n",
      " 0.8239004  0.82921785 0.83883991 0.82923192 0.84950295 0.84632374\n",
      " 0.80148175 0.83667822 0.83883053 0.81641188 0.82387695 0.84097346\n",
      " 0.82388633 0.83885398 0.84097815 0.80146768 0.83457282 0.83136546\n",
      " 0.80040794 0.83671106 0.83243458 0.80360123 0.8239004  0.83137485\n",
      " 0.8003798  0.83563256 0.82922254 0.80573946 0.82070712 0.82389571\n",
      " 0.80576292 0.82174809 0.82496483 0.80575354 0.8324252  0.8313467\n",
      " 0.80362468 0.83244866 0.82281721 0.81217294 0.82710776 0.82495545\n",
      " 0.80685549 0.83137016 0.84095    0.81748569 0.81535684 0.83029635\n",
      " 0.8036153  0.82925068 0.83243458 0.80358715 0.83883991 0.8281628\n",
      " 0.80043609 0.83135139 0.84204257 0.80468911 0.83667822 0.83029635\n",
      " 0.8239004  0.83671106 0.83777548 0.82818626 0.83243927 0.8324252\n",
      " 0.83883053 0.85056737 0.84631436 0.83031042 0.82283128 0.8249789\n",
      " 0.82816749 0.84418081 0.8281628  0.83989496 0.83028227 0.83669229\n",
      " 0.82496952 0.82387225 0.83991841 0.81534276 0.83562317 0.83351308\n",
      " 0.81642126 0.82283128 0.83030573 0.82281252 0.82815811 0.82708899\n",
      " 0.8110616  0.82388164 0.82707023 0.81748569 0.82708899 0.82280783\n",
      " 0.81959578 0.82601987 0.83136077 0.82603395 0.83031042 0.8239004\n",
      " 0.81537091 0.81749507 0.82602456 0.83240644 0.83136077 0.8206649\n",
      " 0.8111132  0.82815811 0.82819564 0.82499767 0.82497421 0.83032918\n",
      " 0.8164025  0.83138423 0.84312577 0.81960047 0.83777079 0.83456344\n",
      " 0.80680858 0.83561848 0.8324252  0.82388164 0.83670167 0.84523586\n",
      " 0.8324252  0.84524055 0.84844321 0.83882584 0.84204257 0.84632374\n",
      " 0.82176686 0.84632374 0.82494606 0.83775672 0.83457751 0.82710306\n",
      " 0.82926476 0.83886337 0.83778017 0.82494606 0.82602926 0.82280783\n",
      " 0.81853135 0.83028227 0.82497421 0.81853605 0.81963331 0.8185595\n",
      " 0.82923192 0.82494137 0.83669698 0.83032918 0.83881176 0.82601049\n",
      " 0.81961455 0.82388164 0.82280783 0.81214479 0.82711245 0.82283128\n",
      " 0.81964269 0.82177624 0.83776141 0.81749038 0.82497421 0.82602456\n",
      " 0.81214948 0.80359184 0.82172933 0.817481   0.81752322 0.82812058\n",
      " 0.82604333 0.82285474 0.83029635]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.4, 'max_depth': 3, 'max_features': 4, 'n_estimators': 10}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'n_estimators': [5, 10, 20],\n",
    "                    'max_depth': list(range(2,9)),\n",
    "                    'learning_rate': list(np.linspace(.1, .5, 5)),\n",
    "                    'max_features': [2, 3, 4]}]\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), tuned_parameters, cv=kf, scoring='recall', n_jobs=4)\n",
    "clf.fit(X, y)\n",
    "print(clf.cv_results_['mean_fit_time'].mean())\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about xgboost (vs sklearn's GBM)\n",
    "\n",
    "Sometimes knowns as \"regularized\" GBM, more robust to overfitting.\n",
    "\n",
    "Has more flexibility in defining weak learners, and objective function.\n",
    "\n",
    "Reputation of being very fast.\n",
    "\n",
    "From the same author as the one above:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 1}\n",
      "0.1086965940869044\n",
      "[0.84736471 0.80480639 0.80691648 0.84204257 0.84097815 0.84738817\n",
      " 0.84204257 0.84096877 0.83883053 0.82918501 0.83455406 0.84417143\n",
      " 0.85482039 0.85910625 0.85590358 0.85164118 0.85591766 0.85058145\n",
      " 0.83346148 0.83775672 0.84205196 0.84628152 0.84736002 0.8473694\n",
      " 0.84523586 0.84736471 0.84844321 0.83241113 0.83667822 0.83138423\n",
      " 0.8366876  0.84948887 0.84951702 0.84309293 0.84416674 0.84523116\n",
      " 0.83882115 0.84202381 0.83883053 0.83562317 0.83988088 0.83883991\n",
      " 0.84202381 0.84416205 0.84414797 0.82707961 0.83455406 0.83242989\n",
      " 0.8420285  0.84308355 0.83777079 0.84415266 0.84309293 0.84415736\n",
      " 0.83774265 0.83561848 0.83245335 0.83989026 0.84306947 0.83456813\n",
      " 0.84628621 0.8420285  0.83670167 0.84415736 0.84309293 0.85484854\n",
      " 0.84095    0.83561379 0.84309293 0.84204257 0.84310231 0.83669229\n",
      " 0.84095469 0.84736471 0.84949826 0.85269154 0.85162711 0.85270092\n",
      " 0.84416205 0.84523586 0.8484479  0.83882115 0.84415266 0.84201912\n",
      " 0.84095938 0.84736471 0.85056737 0.83349901 0.84096407 0.84630967\n",
      " 0.83348963 0.82065552 0.84203788 0.8473694  0.84200974 0.85269623\n",
      " 0.84630967 0.83987619 0.84309762 0.83560441 0.84095    0.84527338\n",
      " 0.83454467 0.84630497 0.84096877 0.84097346 0.83883522 0.84095469\n",
      " 0.8195864  0.8366876  0.83455875 0.82494137 0.84307416 0.8420285\n",
      " 0.83349432 0.83881646 0.83562786 0.82494606 0.84307416 0.83883522\n",
      " 0.8324252  0.85375596 0.84522647 0.83882584 0.85269623 0.83775203\n",
      " 0.85588482 0.85375596 0.84524993 0.84201912 0.83349432 0.83990434\n",
      " 0.83777548 0.83456344 0.84202381 0.83349901 0.84524993 0.84950295\n",
      " 0.84843852 0.84524524 0.85057676 0.84309293 0.83882584 0.85058614\n",
      " 0.83672044 0.8473694  0.84309293 0.83454936 0.8473694  0.85057207\n",
      " 0.83457751 0.82923192 0.84309762 0.83241113 0.84523586 0.84633312\n",
      " 0.8377661  0.83989496 0.84630967 0.83883053 0.83352247 0.83882115\n",
      " 0.83346148 0.83243458 0.83350839 0.82920846 0.83882584 0.84096877\n",
      " 0.83027758 0.83561379 0.83562317 0.82601049 0.84097346 0.83349901\n",
      " 0.8260058  0.8377661  0.8462909  0.82495075 0.84095938 0.84628152\n",
      " 0.83242051 0.82919439 0.82921785 0.82919908 0.82388164 0.84096877\n",
      " 0.82815811 0.82385818 0.83029635 0.8505533  0.84949826 0.83777548\n",
      " 0.83133732 0.83883991 0.83883522 0.83883522 0.82603864 0.83775672\n",
      " 0.83562786 0.85164118 0.86660415 0.83561848 0.84630028 0.85485323\n",
      " 0.83137485 0.83351777 0.83990434 0.8388446  0.85165526 0.85591766\n",
      " 0.82708899 0.84095    0.84737409 0.82601987 0.84203319 0.84416205\n",
      " 0.83988557 0.84417143 0.85698678 0.82173871 0.84094531 0.84630028\n",
      " 0.83349901 0.84522178 0.84096407 0.82494606 0.83241582 0.84737409\n",
      " 0.82389102 0.83559972 0.83562317 0.83029166 0.83347086 0.83348494\n",
      " 0.82923192 0.82921785 0.83671575 0.82707023 0.82812996 0.83776141\n",
      " 0.83564194 0.83135608 0.83134201 0.83666884 0.81960047 0.84415736\n",
      " 0.83028227 0.82601049 0.84097346 0.83136546 0.82919908 0.83351308\n",
      " 0.85694925 0.85163649 0.85375596 0.84308355 0.84418081 0.843107\n",
      " 0.83776141 0.83563256 0.83562317 0.8420285  0.84097346 0.8527103\n",
      " 0.8366876  0.84096877 0.84737878 0.83456813 0.82923192 0.8324252\n",
      " 0.8377661  0.8516318  0.85057207 0.82815811 0.82922254 0.84095938\n",
      " 0.82070243 0.83242051 0.85268216 0.83456344 0.84414797 0.86446591\n",
      " 0.82068835 0.83668291 0.85270092 0.817481   0.83133732 0.83240175\n",
      " 0.83561848 0.83883053 0.85592235 0.83348963 0.83133732 0.83989026\n",
      " 0.82495075 0.82281252 0.83241113 0.81962393 0.83347555 0.84738817\n",
      " 0.82920846 0.82600111 0.83882584 0.82708899 0.82922723 0.83561848\n",
      " 0.83242989 0.83239705 0.83884929 0.8313467  0.82706554 0.84095938\n",
      " 0.83349901 0.82707961 0.83242051]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.4, 'max_depth': 3, 'n_estimators': 5, 'subsample': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "print(XGBClassifier().get_params())\n",
    "tuned_parameters = [{'n_estimators': [5, 20, 50],\n",
    "                    'max_depth': list(range(2,9)),\n",
    "                    'learning_rate': list(np.linspace(.1, .5, 5)),\n",
    "                    'subsample': [.5, .8, 1.]}]\n",
    "clf = GridSearchCV(XGBClassifier(), tuned_parameters, cv=kf, scoring='recall', n_jobs=4)\n",
    "clf.fit(X, y)\n",
    "print(clf.cv_results_['mean_fit_time'].mean())\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtleties in parameter optimization: See additional notebook\n",
    "\n",
    "-  Use cv_results to look at gradients along algorithms and build understanding;\n",
    "\n",
    "-  Push the edges of your parameter grid search; \n",
    "\n",
    "-  Do nested cross validation to optimize parameters in order to avoid leakage between the parameter optimization and the cross validation procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for advanced optimization (know your data).\n",
    "\n",
    "Flip data so less common class becomes the positive one and check performance (in particular, recall). Introduce the \"class weight\" parameter for unbalanced data sets where we are interested in the \"uncommon\" class; define and use ad-hoc metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1 - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425312214950168 0.003949757494078978\n",
      "0.960272417707151 0.9699610181151113 0.9427180831149382\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "cross_val = cross_val_score(rfc, X, y)\n",
    "print(cross_val.mean(), cross_val.std())\n",
    "y_pred = cross_val_predict(rfc, X, y, cv=kf)\n",
    "print(metrics.recall_score(y, y_pred), \n",
    "      metrics.precision_score(y, y_pred), \n",
    "      metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The class weight parameter\n",
    "\n",
    "In SVMs, C, the soft margin parameter, can take different values according to class. <b> This is helpful for imbalanced data sets, where we are interested in the less common objects. </b> This parameter is available for other estimators too!\n",
    "\n",
    "<img src=\"Strata_images/SVM_8.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40176353 0.39667835 0.39896574 0.38918166 0.40040269 0.36251583]\n",
      "[0.89966305 0.91276675 0.93111194 0.94140771 0.9421565  0.92362411]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0: 2, 1: 1}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'class_weight': [{0:1, 1:100}, {0:1, 1:20}, {0:1, 1:4}, {0:1, 1:2}, {0:2, 1:1}, {0:5, 1:1}]}]\n",
    "clf = GridSearchCV(RandomForestClassifier(max_depth=3, max_features=4, \n",
    "                                          min_samples_split=2, n_estimators=35), \n",
    "                   tuned_parameters, cv=kf, scoring='accuracy', n_jobs=4)\n",
    "clf.fit(X, y)\n",
    "print(clf.cv_results_['mean_fit_time'])\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My advice: Define your own evaluation metric \n",
    "\n",
    "This is an example of what we did for this paper (Leung, VA et al 2016), where x0 = 1 - precision and x1 = 1 - recall.\n",
    "\n",
    "<img src=\"Strata_images/Formula_Leung.jpg\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9618615209988649 0.9669100867183934 0.9414077124672408\n",
      "Confusion matrix, without normalization\n",
      "0.03308991328160657 0.0330899132816066 0.038138479001135095 0.038138479001135095\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "y_pred = cross_val_predict(rfc, X, y, cv=kf)\n",
    "print(metrics.recall_score(y, y_pred), \n",
    "      metrics.precision_score(y, y_pred), \n",
    "      metrics.accuracy_score(y, y_pred))\n",
    "conf_matrix = confusion_matrix(y, y_pred, labels=[0,1])\n",
    "plot_confusion_matrix(conf_matrix, classes=['OII', 'LAE'])\n",
    "x_0 = conf_matrix[0,1]/(conf_matrix[0,1]+conf_matrix[1,1])\n",
    "x_1 = 1. - conf_matrix[1,1]/np.sum(conf_matrix[1,:])\n",
    "print(x_0, 1 - metrics.precision_score(y, y_pred), x_1, 1 - metrics.recall_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to do that in code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18297794, -0.17869296, -0.19130135, -0.18945754, -0.18391932])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def my_loss_func(y, ypred):\n",
    "    conf_matrix = confusion_matrix(y, ypred, labels=[0,1])\n",
    "    x_0 = conf_matrix[0,1]/(conf_matrix[0,1]+conf_matrix[1,1])\n",
    "    x_1 = 1. - conf_matrix[1,1]/np.sum(conf_matrix[1,:])\n",
    "    return x_0 + x_1**2 + .5*x_0*x_1 +.15\n",
    "rfc = RandomForestClassifier()\n",
    "cross_val_score(rfc, X, y, cv=kf, scoring=make_scorer(my_loss_func, greater_is_better=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Additional Content\n",
    "\n",
    "-  Notebook 1: Nested Cross Validation (the proper way to optimize parameters), Grid Search best practices, Randomized Grid Search.\n",
    "\n",
    "-  Notebook 2: Diagnostic Tools (Learning Curves, Bias/Variance tradeoff, Feature Importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
